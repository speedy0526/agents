# Minimal Agent System Configuration

# LLM API Key (required)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Custom LLM endpoint (e.g., local Ollama)
# OPENAI_BASE_URL=http://localhost:11434/v1/

# Model name (optional, default: gpt-4o-mini)
# OPENAI_MODEL=gpt-4o-mini

# Concurrency and rate limiting (optional)
# Maximum concurrent API requests (default: 1)
# OPENAI_MAX_CONCURRENT=1

# Maximum retries for rate limit errors (default: 3)
# OPENAI_MAX_RETRIES=3

# Base delay for exponential backoff in seconds (default: 1.0)
# OPENAI_BASE_DELAY=1.0

# Minimum delay between requests in seconds (default: 0.5)
# OPENAI_RATE_LIMIT_DELAY=0.5

# Logging configuration (optional)
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
# LLM_LOG_LEVEL=INFO

# Log detailed request/response content (default: true)
# LLM_LOG_REQUESTS=true
