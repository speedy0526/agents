"""
Stream Manager - é€‚é… Agent.run() ä¸º WebSocket æµå¼è¾“å‡º
"""

import json
import time
import uuid
from typing import Dict, Any, Optional
from fastapi import WebSocket

from .agent import MinimalAgent, Thought


class StreamManager:
    """
    æµå¼è¾“å‡ºç®¡ç†å™¨ï¼Œå°† Agent æ‰§è¡Œè¿‡ç¨‹å®æ—¶æ¨é€åˆ° WebSocket
    
    æ”¯æŒçš„äº‹ä»¶ç±»å‹ï¼š
    - user_message: ç”¨æˆ·æ¶ˆæ¯
    - agent_thinking: Agent æ€è€ƒè¿‡ç¨‹
    - agent_action: Agent æ‰§è¡ŒåŠ¨ä½œ
    - agent_result: æ‰§è¡Œç»“æœ
    - agent_complete: ä»»åŠ¡å®Œæˆ
    - error: é”™è¯¯ä¿¡æ¯
    """

    def __init__(self, websocket: WebSocket, session_id: str):
        """
        åˆå§‹åŒ– StreamManager

        Args:
            websocket: WebSocket è¿æ¥
            session_id: ä¼šè¯ ID
        """
        self.websocket = websocket
        self.session_id = session_id
        self._abort = False  # ä¸­æ­¢æ ‡å¿—

    def abort(self):
        """ä¸­æ­¢å½“å‰æ‰§è¡Œ"""
        self._abort = True

    async def send_event(self, event_type: str, content: str, metadata: Optional[Dict[str, Any]] = None):
        """
        å‘é€äº‹ä»¶åˆ° WebSocket
        
        Args:
            event_type: äº‹ä»¶ç±»å‹
            content: äº‹ä»¶å†…å®¹
            metadata: é¢å¤–å…ƒæ•°æ®
        """
        message = {
            "event": event_type,
            "content": content,
            "metadata": metadata or {},
            "session_id": self.session_id,
            "timestamp": self._get_timestamp()
        }
        try:
            await self.websocket.send_json(message)
        except Exception as e:
            print(f"WebSocket send error: {e}")

    @staticmethod
    def _get_timestamp() -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        import datetime
        return datetime.datetime.now().isoformat()

    async def think_stream(self, agent: MinimalAgent) -> Thought:
        """
        æµå¼æ‰§è¡Œ think å¹¶å®æ—¶æ¨é€åˆ° WebSocket

        Args:
            agent: MinimalAgent å®ä¾‹

        Returns:
            Thought å¯¹è±¡
        """
        messages = agent.context.get_messages(include_goals=True)

        # Build meta instruction for Thought generation
        meta_instruction = """<OUTPUT_FORMAT>
You must respond with JSON using ONLY these fields:

Required fields: reasoning, next_action, tool_name (optional), tool_parameters (optional), subagent_type (optional), subagent_command (optional)

Schema:
{
  "reasoning": "Your reasoning process",
  "next_action": "One of: use_tool, use_skill, call_chain, think, respond_to_user, finish",
  "tool_name": "Name of tool to use (if next_action='use_tool')",
  "tool_parameters": {"param1": "value1"},
  "subagent_type": "Type of SubAgent (skill, tool, chain)",
  "subagent_command": "Command for SubAgent"
}

CRITICAL RULES:
1. Your entire response must be a single JSON object
2. Use ONLY the exact field names listed above
3. Do NOT include any fields like 'query', 'search', 'answer', etc.
4. Do NOT wrap in markdown code blocks
5. Output nothing except the JSON object

Examples:
- To use a tool: {"reasoning": "I need to search", "next_action": "use_tool", "tool_name": "search_google", "tool_parameters": {"query": "Python"}}
- To use a skill: {"reasoning": "I need to research", "next_action": "use_skill", "subagent_type": "skill", "subagent_command": "research"}
- To finish: {"reasoning": "Task complete", "next_action": "finish"}
</OUTPUT_FORMAT>"""

        messages_with_instruction = [
            {"role": "system", "content": meta_instruction},
            *messages,
        ]

        # ä½¿ç”¨ LLM çš„æµå¼ API
        full_content = ""
        start = time.time()

        # å‘é€æ€è€ƒå¼€å§‹äº‹ä»¶
        await self.send_event("agent_thinking", "ğŸ’­ Thinking...")

        try:
            # ä½¿ç”¨ç°æœ‰çš„æµå¼æ¥å£
            params = {"model": agent.llm.model, "messages": messages_with_instruction, "stream": True}
            stream = await agent.llm.client.chat.completions.create(**params)

            async for chunk in stream:
                # æ£€æŸ¥ä¸­æ­¢æ ‡å¿—
                if self._abort:
                    break

                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_content += content
                    # å®æ—¶å‘é€æ€è€ƒå†…å®¹
                    await self.send_event("agent_thinking", content)

            # è§£æ JSON
            json_text = agent.llm._extract_json(full_content)
            parsed = json.loads(json_text)
            parsed = agent.llm._ensure_object(parsed)

            return Thought.model_validate(parsed)

        except Exception as e:
            duration = time.time() - start
            await self.send_event("error", f"Thinking failed: {e}")
            raise

    async def stream_agent_run(self, agent: MinimalAgent, user_request: str, max_steps: int = 10):
        """
        æ‰§è¡Œ Agent å¹¶æµå¼è¾“å‡ºäº‹ä»¶åˆ° WebSocket

        ä¿®æ”¹è‡ª MinimalAgent.run()ï¼Œåœ¨å…³é”®æ­¥éª¤æ’å…¥ WebSocket æ¨é€é€»è¾‘

        Args:
            agent: MinimalAgent å®ä¾‹
            user_request: ç”¨æˆ·è¯·æ±‚
            max_steps: æœ€å¤§æ‰§è¡Œæ­¥æ•°
        """
        # å‘é€ç”¨æˆ·æ¶ˆæ¯äº‹ä»¶
        await self.send_event("user_message", user_request)

        # Generate unique session ID for this run
        session_id = uuid.uuid4().hex[:8]

        # Create new context manager for this session
        agent.context = agent.context.__class__(
            max_context_length=20000,
            workspace_dir=agent.workspace_dir,
            auto_save=True,
            min_save_interval=0.5,
            session_id=session_id,
        )

        # Add system prompt to new context
        agent.context.add_system_prompt(agent.get_system_prompt())
        agent.context.save()

        # Add user request
        agent.context.add_user_request(user_request)

        # Set initial goals from request
        agent.context.set_goals([f"Complete: {user_request}"])

        # å‘é€åˆå§‹ä¿¡æ¯
        await self.send_event("agent_info", f"Ready. Tools: {len(agent.tools)}, Skills: {', '.join(agent.skill_manager.get_skill_names()) or 'None'}")

        for step in range(max_steps):
            # æ£€æŸ¥ä¸­æ­¢æ ‡å¿—
            if self._abort:
                await self.send_event("agent_info", "âš ï¸ ä»»åŠ¡å·²è¢«ä¸­æ­¢")
                return "Task aborted by user"

            # Compress context if needed
            agent.context.compress_if_needed()

            # Think with streaming
            thought = await self.think_stream(agent)
            agent.context.add_thought(thought.reasoning)

            # Safety check
            if step >= 5 and not agent.context.shared_memory.get("has_tangible_results"):
                agent.context.add_system_prompt(f"""
### Progress Check

You have taken {step + 1} steps but haven't produced tangible results yet.
Consider if you should:
1. Actually execute the tools/skills to produce results, OR
2. Set next_action='finish' if the task is somehow complete, OR  
3. Respond to user asking for clarification

Remember: Activating a skill or tool is not the same as completing the task.
""")

            # Check if finished
            if thought.next_action == "finish":
                agent.context.add_assistant_response(thought.reasoning)
                await self.send_event("agent_complete", thought.reasoning)
                return thought.reasoning

            # Check if should think more
            if thought.next_action == "think":
                await self.send_event("agent_thinking", "Continuing reasoning...")
                continue

            # Check if should respond to user
            if thought.next_action == "respond_to_user":
                agent.context.add_assistant_response(thought.reasoning)
                await self.send_event("agent_result", thought.reasoning)
                return thought.reasoning

            # Execute SubAgent
            try:
                # å‘é€åŠ¨ä½œäº‹ä»¶
                await self.send_event(
                    "agent_action",
                    f"Executing: {thought.next_action}",
                    {
                        "action_type": thought.next_action,
                        "tool_name": thought.tool_name,
                        "subagent_type": thought.subagent_type,
                        "subagent_command": thought.subagent_command
                    }
                )

                subagent_result = await agent.execute_subagent(thought)

                if subagent_result is None:
                    # Not a SubAgent action
                    await self.send_event("agent_thinking", "Not a SubAgent action, skipping...")
                    continue

                # å‘é€ç»“æœäº‹ä»¶
                await self.send_event(
                    "agent_result",
                    subagent_result.summary or "SubAgent executed successfully",
                    {
                        "success": subagent_result.success,
                        "error": subagent_result.error,
                        "metadata": subagent_result.metadata
                    }
                )

            except Exception as e:
                # Log error to context
                agent.context.add_assistant_response(
                    f"SubAgent execution error: {str(e)}"
                )
                # å‘é€é”™è¯¯äº‹ä»¶
                await self.send_event("error", f"SubAgent execution error: {str(e)}")

        return "Maximum steps reached. Task incomplete."
